{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "import random\n",
    "\n",
    "sys.path.append( os.path.abspath('..') )\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path('Datasets').mkdir(exist_ok=True)\n",
    "os.chdir('Datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_grid(imgs, labels, width, height, **kwargs):\n",
    "    fig = plt.figure()\n",
    "    for i in range(width * height):\n",
    "        ax = plt.subplot(height, width, i + 1)\n",
    "        plt.imshow(imgs[i], **kwargs)\n",
    "        plt.xlabel(labels[i])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plot_image_grid(x_train, y_train, width=8, height=5, cmap='gray_r', vmin=0, vmax=255)\n",
    "fig.savefig('MNIST.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test_, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "num_to_label = ['T-Shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 5\n",
    "width = 8\n",
    "labels = [num_to_label[num] for num in y_train[0:width*height]]\n",
    "fig = plot_image_grid(x_train, labels, width, height, cmap='gray_r', vmin=0, vmax=255)\n",
    "fig.savefig('Fashion_MNIST.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 CIFAR 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test_, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "num_to_label = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 5\n",
    "width = 8\n",
    "labels = [num_to_label[num] for num in y_train[0:width*height, 0]]\n",
    "fig = plot_image_grid(x_train, labels, width, height, vmin=0, vmax=255)\n",
    "fig.set_size_inches(8, 6)\n",
    "fig.savefig('CIFAR10.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Flowers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset must be downloaded separedly, you can find it in this link:\n",
    "https://www.robots.ox.ac.uk/~vgg/data/flowers/102/index.html\n",
    "\n",
    "After downloading, make sure the folder structure is as follows:\n",
    "```\n",
    "ðŸ“‚<PARENT> \n",
    " â”— ðŸ“‚flowers \n",
    "    â”— ðŸ“‚imgs \n",
    "       â”£ ðŸ“„image_00001.jpg\n",
    "       â”£ ðŸ“„image_00002.jpg\n",
    "       â”— ðŸ“„ ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Showing original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flowers_parent_path = '<PATH TO FOLDER CONTAINING THE DATASET>'\n",
    "flowers_dir = os.path.join(flowers_parent_path, 'flowers', 'imgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files = os.listdir(flowers_dir)\n",
    "data = []\n",
    "for f in files[1690:1690+12]:\n",
    "    img = tf.keras.preprocessing.image.load_img(os.path.join(flowers_dir, f))\n",
    "    data.append(tf.keras.preprocessing.image.img_to_array(img, dtype='uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(3 * 4):\n",
    "    ax = plt.subplot(3, 4, i + 1)\n",
    "    plt.imshow(data[i])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('Flowers.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Showing reduced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to have created the reduced dataset first by running the code in the file `datasets_preprocess.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(os.path.join('..', '..', 'flowers.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 279923  # https://youtu.be/nWSFlqBOgl8?t=86  -  I love this song\n",
    "random.seed(SEED)\n",
    "\n",
    "indexes = [*range(2, 2 + 60*30, 30)]\n",
    "random.shuffle(indexes)\n",
    "samples = data[indexes].astype('float32') / 255\n",
    "\n",
    "grid = utils.fn.make_grid_image(samples, n_cols=10, border=1, pad=1)\n",
    "fig = plt.figure()\n",
    "plt.imshow(grid)\n",
    "plt.axis(False)\n",
    "plt.tight_layout(h_pad=0, w_pad=0)\n",
    "fig.savefig('Flowers_reduced.pdf', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 CelebA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset must be downloaded separedly, you can find it in this link:\n",
    "http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html\n",
    "\n",
    "After downloading, make sure the folder structure is as follows:\n",
    "```\n",
    "ðŸ“‚<PARENT> \n",
    " â”— ðŸ“‚celeba \n",
    "    â”— ðŸ“‚imgs \n",
    "       â”£ ðŸ“„000001.jpg \n",
    "       â”£ ðŸ“„000002.jpg \n",
    "       â”— ðŸ“„ ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Showing original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celeba_parent_path = '<PATH TO FOLDER CONTAINING THE DATASET>'\n",
    "celeba_dir = os.path.join(celeba_parent_path, 'celeba', 'imgs')\n",
    "files = os.listdir(celeba_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for f in files[252:252+100]:\n",
    "    img = tf.keras.preprocessing.image.load_img(os.path.join(celeba_dir, f))\n",
    "    data.append(tf.keras.preprocessing.image.img_to_array(img, dtype='uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(3 * 4):\n",
    "    ax = plt.subplot(3, 4, i + 1)\n",
    "    plt.imshow(data[i])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('CelebA.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Showing reduced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to have created the reduced dataset first by running the code in the file `datasets_preprocess.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(os.path.join('..', '..', 'celeba.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = data[68:68+60].astype('float32') / 255\n",
    "grid = utils.fn.make_grid_image(samples, n_cols=10, border=1, pad=1)\n",
    "fig = plt.figure()\n",
    "plt.imshow(grid)\n",
    "plt.axis(False)\n",
    "plt.tight_layout(h_pad=0, w_pad=0)\n",
    "fig.savefig('CelebA_reduced.pdf', bbox_inches='tight', pad_inches=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
