{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66bfb14c",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80c96ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_gan as tfgan\n",
    "import numpy as np\n",
    "import os, sys\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append( os.path.abspath('..') )\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4dcaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path('Flowers').mkdir(exist_ok=True)\n",
    "os.chdir('Flowers')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7b5dbb",
   "metadata": {},
   "source": [
    "Loading the preprocessed Flowers dataset, make sure to execute the code found at `Other/Preprocessing.ipynb` in order to create this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ced4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(np.load(os.path.join('..', '..', 'flowers.npy')))\n",
    "dataset = dataset.map(lambda img: (tf.cast(img, tf.float32) - 127.5) / 127.5)\n",
    "NUM_IMAGES = int(dataset.cardinality())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bd8a0f",
   "metadata": {},
   "source": [
    "## 1 Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60877624",
   "metadata": {},
   "source": [
    "### 1.1 Architecure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091bdf0a",
   "metadata": {},
   "source": [
    "In these experiments the use of Batch Normalization has shown to produce artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a82d33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_model_transp_conv(latent_dims):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(6*6*512, input_shape=(latent_dims,)),\n",
    "        tf.keras.layers.LeakyReLU(0.2),\n",
    "        # tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Reshape((6, 6, 512)),\n",
    "        # Output Shape: 6x6x512\n",
    "        \n",
    "        tf.keras.layers.Conv2DTranspose(256, kernel_size=2, strides=2, padding='same'),\n",
    "        tf.keras.layers.LeakyReLU(0.2),\n",
    "        # tf.keras.layers.BatchNormalization(),\n",
    "        # Output Shape: 12x12x256\n",
    "        \n",
    "        tf.keras.layers.Conv2DTranspose(128, kernel_size=2, strides=2, padding='same'),\n",
    "        tf.keras.layers.LeakyReLU(0.2),\n",
    "        # tf.keras.layers.BatchNormalization(),\n",
    "        # Output Shape: 24x24x128\n",
    "        \n",
    "        tf.keras.layers.Conv2DTranspose(64, kernel_size=2, strides=2, padding='same'),\n",
    "        tf.keras.layers.LeakyReLU(0.2),\n",
    "        # tf.keras.layers.BatchNormalization(),\n",
    "        # Output Shape: 48x48x64\n",
    "        \n",
    "        tf.keras.layers.Conv2D(3, kernel_size=1, strides=1, padding='same', activation='tanh')\n",
    "        # Output Shape: 48x48x3\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22221c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_model_upsample(latent_dims, interpolation):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(6*6*512, input_shape=(latent_dims,)),\n",
    "        tf.keras.layers.LeakyReLU(0.2),\n",
    "        # tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Reshape((6, 6, 512)),\n",
    "        # Output Shape: 6x6x512\n",
    "        \n",
    "        tf.keras.layers.UpSampling2D(size=2, interpolation=interpolation),\n",
    "        tf.keras.layers.Conv2D(256, kernel_size=3, strides=1, padding='same'),\n",
    "        tf.keras.layers.LeakyReLU(0.2),\n",
    "        # tf.keras.layers.BatchNormalization(),\n",
    "        # Output Shape: 12x12x256\n",
    "        \n",
    "        tf.keras.layers.UpSampling2D(size=2, interpolation=interpolation),\n",
    "        tf.keras.layers.Conv2D(128, kernel_size=3, strides=1, padding='same'),\n",
    "        tf.keras.layers.LeakyReLU(0.2),\n",
    "        # tf.keras.layers.BatchNormalization(),\n",
    "        # Output Shape: 24x24x128\n",
    "        \n",
    "        tf.keras.layers.UpSampling2D(size=2, interpolation=interpolation),\n",
    "        tf.keras.layers.Conv2D(64, kernel_size=3, strides=1, padding='same'),\n",
    "        tf.keras.layers.LeakyReLU(0.2),\n",
    "        # tf.keras.layers.BatchNormalization(),\n",
    "        # Output Shape: 48x48x64\n",
    "        \n",
    "        tf.keras.layers.Conv2D(3, kernel_size=1, strides=1, padding='same', activation='tanh')\n",
    "        # Output Shape: 48x48x3\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d30f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_model():\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(64, kernel_size=1, strides=2, padding='same', input_shape=(48,48,3)),\n",
    "        tf.keras.layers.LeakyReLU(0.2),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        # Output Shape: 48x48x64\n",
    "        \n",
    "        tf.keras.layers.Conv2D(128, kernel_size=3, strides=2, padding='same'),\n",
    "        tf.keras.layers.LeakyReLU(0.2),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        # Output Shape: 24x24x128\n",
    "        \n",
    "        tf.keras.layers.Conv2D(256, kernel_size=3, strides=2, padding='same'),\n",
    "        tf.keras.layers.LeakyReLU(0.2),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        # Output Shape: 12x12x256\n",
    "        \n",
    "        tf.keras.layers.Conv2D(512, kernel_size=3, strides=2, padding='same'),\n",
    "        tf.keras.layers.LeakyReLU(0.2),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        # Output Shape: 6x6x512\n",
    "\n",
    "        tf.keras.layers.Conv2D(512, kernel_size=6, strides=1, padding='same'),\n",
    "        tf.keras.layers.LeakyReLU(0.2),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        # Output Shape: 1x1x512\n",
    "\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2351eaef",
   "metadata": {},
   "source": [
    "### 1.2 Losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1f8296",
   "metadata": {},
   "source": [
    "The binary cross entropy (BCE) between $y$ and $\\hat{y}$ is calculated as:\n",
    "\n",
    "$$\n",
    "    \\mathrm{BCE}(y, \\hat{y}) = - y \\log\\left(\\hat{y}\\right) - (1-y) \\log\\left(1 - \\hat{y}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db60d5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fb4085",
   "metadata": {},
   "source": [
    "The generator tries to maximize the chance of the discriminator being wrong. This is equivalent of trying to minimize the following loss function:\n",
    "\n",
    "$$\n",
    "    J^{(G)} = -\\log\\bigl(D\\bigl(G(z)\\bigr)\\bigr)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3fcad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace7e009",
   "metadata": {},
   "source": [
    "The discriminator tries to correctly classify real data as real and fake data as fake. This is equivalent to minimizing the following loss function:\n",
    "\n",
    "$$\n",
    "    J^{(D)} = -\\log\\bigr(D(x)\\bigl) - \\log\\bigl(1 - D\\bigl(G(z)\\bigr)\\bigr)\n",
    "$$\n",
    "\n",
    "Here we scale down the loss by a factor of $\\;0.5$ and apply a one sided label smoothing of $\\:0.9$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb44540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(0.9*tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    return 0.5 * (real_loss + fake_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100851c8",
   "metadata": {},
   "source": [
    "## 2 Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0a1861",
   "metadata": {},
   "source": [
    "### 2.1 Main functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf05b0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_train_step(generator, discriminator, images, latent_dims):\n",
    "    noise = tf.random.normal([images.shape[0], latent_dims])\n",
    "    with tf.GradientTape() as disc_tape:\n",
    "        generated_imgs = generator(noise, training=True)\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_imgs, training=True)\n",
    "        loss_D = discriminator_loss(real_output, fake_output)\n",
    "    \n",
    "    grads_D = disc_tape.gradient(loss_D, discriminator.trainable_variables)\n",
    "    discriminator.optimizer.apply_gradients(zip(grads_D, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21995a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_train_step(generator, discriminator, batch_size, latent_dims):\n",
    "    noise = tf.random.normal([batch_size, latent_dims])\n",
    "    with tf.GradientTape() as gen_tape:\n",
    "        generated_imgs = generator(noise, training=True)\n",
    "        fake_output = discriminator(generated_imgs, training=True)\n",
    "        loss_G = generator_loss(fake_output)\n",
    "    \n",
    "    grads_G = gen_tape.gradient(loss_G, generator.trainable_variables)\n",
    "    generator.optimizer.apply_gradients(zip(grads_G, generator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c886c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(generator, discriminator, dataset, epochs, batch_size, callbacks=None):\n",
    "    latent_dims = generator.input_shape[1]\n",
    "    num_batches = int(1 + (NUM_IMAGES - 1) // batch_size)\n",
    "    \n",
    "    generator_step = tf.function(generator_train_step)\n",
    "    discriminator_step = tf.function(discriminator_train_step)\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        for c in callbacks:\n",
    "            c.on_epoch_begin(epoch=epoch + 1, generator=generator, discriminator=discriminator)\n",
    "        \n",
    "        for batch in tqdm(dataset, leave=False, total=num_batches):\n",
    "            discriminator_step(generator, discriminator, batch, latent_dims)\n",
    "            generator_step(generator, discriminator, batch_size, latent_dims)\n",
    "        \n",
    "        for c in callbacks:\n",
    "            c.on_epoch_end(epoch=epoch + 1, generator=generator, discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd662e0",
   "metadata": {},
   "source": [
    "### 2.2 Hyperparameter Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f10559",
   "metadata": {},
   "source": [
    "These were the hyperparameters tested for the final document. Training all of them simultaneously may take a long time, consider commenting out some options to run the tests individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cd5157",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 24\n",
    "LATENT_DIMS = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8411b5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams_list = [\n",
    "    {'upsample': 'TrpConv',  'epochs':  20},\n",
    "    {'upsample': 'bilinear', 'epochs':  20},\n",
    "    {'upsample': 'nearest',  'epochs': 100}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6645241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hparams in hparams_list:\n",
    "    dirname = '{}'.format(hparams['upsample'].upper())\n",
    "    Path(dirname).mkdir(exist_ok=True)\n",
    "    \n",
    "    ## Models\n",
    "    if hparams['upsample'] is 'TrpConv':\n",
    "        generator = generator_model_transp_conv(LATENT_DIMS)\n",
    "    else:\n",
    "        generator = generator_model_upsample(LATENT_DIMS, hparams['upsample'])\n",
    "    generator.optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.0)\n",
    "\n",
    "    discriminator = discriminator_model()\n",
    "    discriminator.optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.0)\n",
    "    \n",
    "    ## Callbacks\n",
    "    timer = utils.callback.TimerCallback()\n",
    "    save_samples = utils.callback.SaveSamplesCallback(\n",
    "        path_format=os.path.join(dirname, 'epoch-{}'),\n",
    "        inputs=tf.random.normal((8*8, LATENT_DIMS)),\n",
    "        n_cols=8,\n",
    "        savefig_kwargs={'bbox_inches': 'tight', 'pad_inches': 0, 'dpi': 256},\n",
    "        grid_params={'border':2, 'pad':2, 'pad_value':0.0},\n",
    "        transform_samples=lambda samples: (1 + samples) * 0.5\n",
    "    )\n",
    "    \n",
    "    ## Train and save results\n",
    "    train(\n",
    "        generator,\n",
    "        discriminator,\n",
    "        dataset=dataset.shuffle(NUM_IMAGES).batch(BATCH_SIZE),\n",
    "        epochs=hparams['epochs'],\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks=[timer, save_samples]\n",
    "    )\n",
    "    \n",
    "    generator.save    (os.path.join(dirname, 'generator.h5'    ), overwrite=True, save_format='h5')\n",
    "    discriminator.save(os.path.join(dirname, 'discriminator.h5'), overwrite=True, save_format='h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
